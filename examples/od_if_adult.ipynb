{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alibi\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from alibi_detect.od import IForest\n",
    "from alibi_detect.utils.perturbation import inject_outlier_tabular, inject_outlier_categorical\n",
    "from alibi_detect.utils.saving import save_detector, load_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load adult dataset\n",
    "\n",
    "The ```fetch_adult``` function returns a ```Bunch``` object containing the features, the targets, the feature names and a mapping of the categories in each categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = alibi.datasets.fetch_adult()\n",
    "X, y = adult.data, adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define shuffled train, validation (to find outlier threshold) and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "Xy_perm = np.random.permutation(np.c_[X, y])\n",
    "X, y = Xy_perm[:,:-1], Xy_perm[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 12) (25000,) (5000, 12) (5000,) (2561, 12) (2561,)\n"
     ]
    }
   ],
   "source": [
    "n_train = 25000\n",
    "n_valid = 5000\n",
    "X_train, y_train = X[:n_train,:], y[:n_train]\n",
    "X_valid, y_valid = X[n_train:n_train+n_valid,:], y[n_train:n_train+n_valid]\n",
    "X_test, y_test = X[n_train+n_valid:,:], y[n_train+n_valid:]\n",
    "print(X_train.shape, y_train.shape, \n",
    "      X_valid.shape, y_valid.shape,\n",
    "      X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create outliers\n",
    "\n",
    "Inject outliers in both the numerical and categorical features. First we need to know the features for each kind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 11] [0, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "cat_cols = list(category_map.keys())\n",
    "num_cols = [col for col in range(X.shape[1]) if col not in cat_cols]\n",
    "print(cat_cols, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical\n",
    "\n",
    "Now we can add outliers to the validation (or threshold) and test sets. For the numerical data, we need to specify the numerical columns (```cols```), the percentage of outliers (```perc_outlier```), the strength (```n_std```) and the minimum size of the perturbation (```min_std```). The outliers are distributed evenly across the numerical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.54% outliers\n"
     ]
    }
   ],
   "source": [
    "perc_outlier = 10\n",
    "data = inject_outlier_tabular(X_valid, num_cols, perc_outlier, n_std=3., min_std=1.)\n",
    "X_threshold, y_threshold = data.data, data.target\n",
    "X_threshold_, y_threshold_ = X_threshold.copy(), y_threshold.copy()  # store for comparison later\n",
    "print('{:.2f}% outliers'.format(100 * y_threshold.sum() / len(y_threshold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect an instance that was changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age changed by -15.48.\n"
     ]
    }
   ],
   "source": [
    "outlier_idx = np.where(y_threshold != 0)[0]\n",
    "vdiff = X_threshold[outlier_idx[0]] - X_valid[outlier_idx[0]]\n",
    "fdiff = np.where(vdiff != 0)[0]\n",
    "print('{} changed by {:.2f}.'.format(feature_names[fdiff[0]], vdiff[fdiff[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = inject_outlier_tabular(X_test, num_cols, perc_outlier, n_std=3., min_std=1.)\n",
    "X_outlier, y_outlier = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical\n",
    "\n",
    "It is much trickier to perturb categorical features towards outliers. Consider for instance the *Education* feature. It is easy to see that the category *(high school) Dropout* is very dissimilar from *Doctorate*. So if we want to create an outlier starting from an instance with *Education* equal to *Dropout*, we would like to obtain an instance where the value changes to e.g. *Prof-School* or *Doctorate*. Other features however don't have a natural order like *Country* or *Relationship*. \n",
    "\n",
    "In order to obtain a meaningful perturbation, we first compute the pairwise distances between categories of a categorical variable based on the context provided by the other variables in the dataset. This method is based on the *Association-Based Distance Metric* (ABDM) developed by [Le et al (2005)](http://www.jaist.ac.jp/~bao/papers/N26.pdf). ABDM computes a dissimilarity measure between categories based on the Kullback-Leibler divergence. We can then apply multidimensional scaling to project the pairwise distances between all the categories into Euclidean space. This method could also help with tree-based models which assume that ordinal-encoded categorical variables are ordered. The reason behind this is that more similar (dissimilar) categories are closer (further) to (from) eachother in Euclidean space.\n",
    "\n",
    "We need to specify the categorical columns (```cols```), the percentage of outliers (```perc_outlier```) and optionally the data we would like to fit the pairwise distances on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = inject_outlier_categorical(X_threshold, cat_cols, perc_outlier, X_fit=X)\n",
    "X_threshold, y_threshold = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = inject_outlier_categorical(X_outlier, cat_cols, perc_outlier, X_fit=X)\n",
    "X_outlier, y_outlier = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check whether the numerical equivalent of the categorical features makes sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(dist, cols, figsize=(10,4)):\n",
    "    dist = dist.reshape(dist.shape[0])\n",
    "    idx = np.argsort(dist)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.bar(cols[idx], dist[idx])\n",
    "    print(cols[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Doctorate' 'Prof-School' 'Masters' 'Bachelors' 'Associates'\n",
      " 'High School grad' 'Dropout']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat = 'Education'\n",
    "idx = feature_names.index(cat)\n",
    "plot_bar(data.d_abs[idx], np.array(category_map[idx]), figsize=(20,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranking for the *Education* feature looks sensible and goes from *Doctorate* to *Dropout*. We can again investigate an instance where the categorical feature has flipped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marital Status changed from Never-Married to Married\n"
     ]
    }
   ],
   "source": [
    "i = 7\n",
    "\n",
    "cat_idx = np.where(y_threshold != y_threshold_)[0]\n",
    "vdiff = X_threshold[cat_idx[i]] - X_threshold_[cat_idx[i]]\n",
    "fdiff = np.where(vdiff != 0)[0]\n",
    "print('{} changed from {} to {}'.format(\n",
    "    feature_names[fdiff[0]],\n",
    "    category_map[fdiff[0]][X_threshold_[cat_idx[i], fdiff[0]].astype(int)],\n",
    "    category_map[fdiff[0]][X_threshold[cat_idx[i], fdiff[0]].astype(int)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define outlier detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:alibi_detect.od.isolationforest:No threshold level set. Need to infer threshold using `infer_threshold`.\n",
      "/home/avl/anaconda3/envs/cdod/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning:\n",
      "\n",
      "default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "\n",
      "/home/avl/anaconda3/envs/cdod/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning:\n",
      "\n",
      "behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "\n",
      "WARNING:alibi_detect.utils.saving:Directory ./models/od_if_adult/ does not exist and is now created.\n"
     ]
    }
   ],
   "source": [
    "# initialize outlier detector\n",
    "od = IForest(threshold=None,  # threshold for outlier score\n",
    "             n_estimators=100)\n",
    "\n",
    "# train\n",
    "od.fit(X_train)\n",
    "\n",
    "# save the trained outlier detector\n",
    "filepath = './models/od_if_adult/'\n",
    "save_detector(od, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* infer threshold and save updated detector\n",
    "\n",
    "* detect outliers\n",
    "\n",
    "* display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cdod] *",
   "language": "python",
   "name": "conda-env-cdod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
