{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Ratio Outlier Detection on Genomes\n",
    "\n",
    "## Method\n",
    "\n",
    "## Dataset\n",
    "\n",
    "## Todo\n",
    "- show in vs. out-of-distribution plot of Fig 1 (incl. log-likelihood vs. GC content)\n",
    "- show in vs. out-of-distribution plot for LLR (incl. GC content plot) + ROC-AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:fbprophet:Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "from alibi_detect.od import LLR\n",
    "from alibi_detect.datasets import fetch_genome\n",
    "from alibi_detect.utils.saving import save_detector, load_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load genome data\n",
    "\n",
    "*X* represents the genomic sequences and *y* whether they are outliers ($1$) or not ($0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 250) (1000000,) (6999774, 250) (6999774,) (7000000, 250) (7000000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = \\\n",
    "        fetch_genome(return_X_y=True, return_labels=False)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no outliers in the training set and a minority of outliers in the validation and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of outliers in train, val and test sets: 0.00, 0.86 and 0.86\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of outliers in train, val and test sets: '\n",
    "      '{:.2f}, {:.2f} and {:.2f}'.format(y_train.mean(), y_val.mean(), y_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model\n",
    "\n",
    "We need to define a generative model which models the genomic sequences. We follow the paper and opt for a simple LSTM. Note that we don't actually need to define the model or `log_prob` function below if we simply load the pretrained detector later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlrLSTM(tf.keras.Model):\n",
    "    def __init__(self, hidden_dim: int, input_dim: int, dropout: float = 0.):\n",
    "        super(LlrLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.lstm = LSTM(hidden_dim, dropout=dropout, return_sequences=True)\n",
    "        self.logits = Dense(input_dim, activation=None)\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        x = tf.one_hot(tf.cast(x, tf.int32), self.input_dim)\n",
    "        x = self.lstm(x)\n",
    "        x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 2000\n",
    "input_dim = 4  # ACGT nucleobases\n",
    "model = LlrLSTM(hidden_dim, input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define our loss function which we can utilize to evaluate our log-likelihood at inference time since the model outputs logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, x):\n",
    "    y = tf.one_hot(tf.cast(y, tf.int32), 4)  # ACGT on-hot encoding\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(y, x, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load or train the outlier detector\n",
    "\n",
    "We can again either fetch the pretrained detector from a [Google Cloud Bucket](https://console.cloud.google.com/storage/browser/seldon-models/alibi-detect/od/llr/genome) or train one from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'my_path'  # change to (absolute) directory where model is downloaded\n",
    "if load_outlier_detector:  # load pretrained outlier detector\n",
    "    detector_type = 'outlier'\n",
    "    dataset = 'genome'\n",
    "    detector_name = 'LikelihoodRatio'\n",
    "    od = fetch_detector(filepath, detector_type, dataset, detector_name)\n",
    "    filepath = os.path.join(filepath, detector_name)\n",
    "else:  # define model, initialize, train and save outlier detector\n",
    "    \n",
    "    od = LLR(threshold=None, model=model, log_prob=loss_fn, sequential=True)\n",
    "    \n",
    "    # train\n",
    "    od.fit()\n",
    "    \n",
    "    # save the trained outlier detector\n",
    "    save_detector(od, filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:detect] *",
   "language": "python",
   "name": "conda-env-detect-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
