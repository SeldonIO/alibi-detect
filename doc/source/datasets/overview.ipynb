{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[source](../api/alibi_detect.datasets.rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The package also contains functionality in `alibi_detect.datasets` to easily fetch a number of datasets for different modalities. For each dataset either the data and labels or a *Bunch* object with the data, labels and optional metadata are returned. Example:\n",
    "\n",
    "```python\n",
    "from alibi_detect.datasets import fetch_ecg\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fetch_ecg(return_X_y=True)\n",
    "```\n",
    "\n",
    "### Financial Data and Market Crises\n",
    "\n",
    "**Financial Crisis Data**: `fetch_financial_crisis`\n",
    "\n",
    "  - Historical financial market data for studying distribution drift during major economic crises. The function provides access to real market data from multiple crisis periods including the 2008 Financial Crisis, 2020 COVID-19 market crash, 2000 Dot-com bubble burst, and 2011 European debt crisis. The data includes equity ETF returns showing correlation structure changes that are ideal for testing spectral drift detection methods. Data is sourced from Yahoo Finance with optional macroeconomic indicators from FRED.\n",
    "\n",
    "```python\n",
    "from alibi_detect.datasets import fetch_financial_crisis\n",
    "\n",
    "# Load 2008 financial crisis data\n",
    "data = fetch_financial_crisis('2008_financial_crisis')\n",
    "pre_crisis_returns = data.data_pre\n",
    "crisis_returns = data.data_crisis\n",
    "\n",
    "# Or return as tuple\n",
    "(pre_data, crisis_data) = fetch_financial_crisis('2008_financial_crisis', return_X_y=True)\n",
    "```\n",
    "\n",
    "**Synthetic Crisis Data**: `create_synthetic_crisis_data`\n",
    "\n",
    "  - Generate controlled synthetic financial returns with configurable correlation structure changes, perfect for benchmarking drift detection methods. Allows precise control over the degree of correlation shift, volatility changes, and number of assets to create datasets with known drift characteristics.\n",
    "\n",
    "```python\n",
    "from alibi_detect.datasets import create_synthetic_crisis_data\n",
    "\n",
    "# Create synthetic data with moderate correlation change\n",
    "data = create_synthetic_crisis_data(\n",
    "    n_assets=8,\n",
    "    pre_correlation=0.30,\n",
    "    crisis_correlation=0.60,\n",
    "    volatility_increase=1.5\n",
    ")\n",
    "print(f\"Expected spectral ratio: {data.spectral_ratio:.3f}\")\n",
    "```\n",
    "\n",
    "**Financial Benchmarks**: `fetch_financial_benchmark`\n",
    "\n",
    "  - Standardized synthetic datasets with predefined characteristics for reproducible drift detection research. Includes benchmarks ranging from mild to severe correlation changes with known expected spectral ratios.\n",
    "\n",
    "```python\n",
    "from alibi_detect.datasets import fetch_financial_benchmark\n",
    "\n",
    "# Load standardized moderate correlation change benchmark\n",
    "benchmark = fetch_financial_benchmark('correlation_change_moderate')\n",
    "expected_ratio = benchmark.expected_spectral_ratio\n",
    "```\n",
    "\n",
    "### Sequential Data and Time Series\n",
    "\n",
    "**Genome Dataset**: `fetch_genome`\n",
    "\n",
    "  - Bacteria genomics dataset for out-of-distribution detection, released as part of [Likelihood Ratios for Out-of-Distribution Detection](https://arxiv.org/abs/1906.02845). From the original *TL;DR*: *The dataset contains genomic sequences of 250 base pairs from 10 in-distribution bacteria classes for training, 60 OOD bacteria classes for validation, and another 60 different OOD bacteria classes for test*. There are respectively 1, 7 and again 7 million sequences in the training, validation and test sets. For detailed info on the dataset check the [README](https://storage.cloud.google.com/seldon-datasets/genome/readme.docx?organizationId=156002945562).\n",
    "  \n",
    "  \n",
    "```python\n",
    "from alibi_detect.datasets import fetch_genome\n",
    "\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = fetch_genome(return_X_y=True)\n",
    "```\n",
    "\n",
    "\n",
    "**ECG 5000**: `fetch_ecg`\n",
    "\n",
    "  - 5000 ECG's, originally obtained from [Physionet](https://archive.physionet.org/cgi-bin/atm/ATM).\n",
    "\n",
    "\n",
    "**NAB**: `fetch_nab`\n",
    "\n",
    "  - Any univariate time series in a DataFrame from the [Numenta Anomaly Benchmark](https://github.com/numenta/NAB). A list with the available time series can be retrieved using `alibi_detect.datasets.get_list_nab()`.\n",
    "\n",
    "\n",
    "### Images\n",
    "\n",
    "**CIFAR-10-C**: `fetch_cifar10c`\n",
    "\n",
    "  - CIFAR-10-C ([Hendrycks & Dietterich, 2019](https://arxiv.org/abs/1903.12261)) contains the test set of CIFAR-10, but corrupted and perturbed by various types of noise, blur, brightness etc. at different levels of severity, leading to a gradual decline in a classification model's performance trained on CIFAR-10. `fetch_cifar10c` allows you to pick any severity level or corruption type. The list with available corruption types can be retrieved with `alibi_detect.datasets.corruption_types_cifar10c()`. The dataset can be used in research on robustness and drift. The original data can be found [here](https://zenodo.org/record/2535967#.XnAM2nX7RNw). Example:\n",
    "  \n",
    "  \n",
    "```python\n",
    "from alibi_detect.datasets import fetch_cifar10c\n",
    "\n",
    "corruption = ['gaussian_noise', 'motion_blur', 'brightness', 'pixelate']\n",
    "X, y = fetch_cifar10c(corruption=corruption, severity=5, return_X_y=True)\n",
    "```\n",
    "\n",
    "  \n",
    "**Adversarial CIFAR-10**: `fetch_attack`\n",
    "\n",
    "  - Load adversarial instances on a ResNet-56 classifier trained on CIFAR-10. Available attacks: [Carlini-Wagner](https://arxiv.org/abs/1608.04644) ('cw') and [SLIDE](https://arxiv.org/abs/1904.13000) ('slide'). Example:\n",
    "  \n",
    "```python\n",
    "from alibi_detect.datasets import fetch_attack\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fetch_attack('cifar10', 'resnet56', 'cw', return_X_y=True)\n",
    "```\n",
    "\n",
    "### Tabular\n",
    "\n",
    "**KDD Cup '99**: `fetch_kdd`\n",
    "\n",
    "  - Dataset with different types of computer network intrusions. `fetch_kdd` allows you to select a subset of network intrusions as targets or pick only specified features. The original data can be found [here](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}