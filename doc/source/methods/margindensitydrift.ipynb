{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[source](../api/alibi_detect.cd.margindensity.rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarginDensity\n",
    "\n",
    "## Overview\n",
    "\n",
    "The margin density drift detector (MD3) ([Sethi and  Kantardzic, 2015](https://www.sciencedirect.com/science/article/pii/S1877050915017871)) quantifies the percentage of predictions made by a probabilistic binary classifier at the decision boundary (as defined by a margin).  This quantity is known as the margin density.  The margin density is compared to an allowable margin density range.  Drift is detected if the calculated margin density for a given batch falls outside of the specified margin density range.  Care should be taken when setting the margin density range.  This can be guided, for example, by calculating the margin density mean and variance on out-of-fold instances when performing k-fold cross-validation, or on data batches from an additional holdout set that are characteristically similar to the data on which the binary classifier was trained.  Low and high margin densities relative to the allowable density range can be indicative of virtual drift, concept drift and/or general changes in model performance.\n",
    "\n",
    "Many alternative drift detection methods focus on tracking changes in the distribution of the data inputs.  These approaches can be prone to generating false positives as they implicitly give equal importance to all features, even those that are of very little importance to the classifier.  The utility of the MD3 approach is that it uses the change in the percentage of samples contained within a classifier's decision boundary (i.e., margin) as a proxy for measuring changes in the probability distribution of the labels given the data inputs, _without actually requiring any labeled data_.  This approach tends to be more robust against false positives as the classifier accounts for differences in feature importances, giving little emphasis to features that do not affect classification performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "### Initialize\n",
    "\n",
    "\n",
    "* `margin`: Width of margin at decision boundary.\n",
    "\n",
    "* `model`: Trained binary classification model.\n",
    "\n",
    "* `density_range`: Tuple of length 2 that defines margin density lower and upper bounds.\n",
    "\n",
    "* `data_type`: Optionally specify the data type (tabular or image). Added to metadata.\n",
    "\n",
    "Initialized drift detector example:\n",
    "\n",
    "```python\n",
    "from alibi_detect.cd import MarginDensityDrift\n",
    "\n",
    "cd = MarginDensityDrift(\n",
    "    margin=0.1,\n",
    "    model=model,\n",
    "    density_range=(0.08,0.12)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Drift\n",
    "\n",
    "We detect data drift by simply calling `predict` on a batch of instances `X`. `return_metric` equal to *True* will also return the drift metric (e.g. accuracy) and the threshold used by the detector.\n",
    "\n",
    "The prediction takes the form of a dictionary with `meta` and `data` keys. `meta` contains the detector's metadata while `data` is also a dictionary which contains the actual predictions stored in the following keys:\n",
    "\n",
    "* `is_drift`: 1 if the sample tested has drifted from the reference data and 0 otherwise.\n",
    "\n",
    "* `margin`: user-defined margin width that is used to define whether or not a prediction .\n",
    "\n",
    "* `margin_density`: calculated value defined by the number of in-margin predictions divided by the total number of samples for a given batch.\n",
    "\n",
    "* `density_range`: or the optional `metric_name` kwarg value: drift metric value if `return_metric` equals *True*.\n",
    "\n",
    "* `direction`: or the optional `metric_name` kwarg value: drift metric value if `return_metric` equals *True*.\n",
    "\n",
    "\n",
    "```python\n",
    "preds_drift = cd.predict(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading\n",
    "\n",
    "The drift detectors can be saved and loaded in the same way as other detectors:\n",
    "\n",
    "```python\n",
    "from alibi_detect.utils.saving import save_detector, load_detector\n",
    "\n",
    "filepath = 'my_path'\n",
    "save_detector(cd, filepath)\n",
    "cd = load_detector(filepath)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "[Drift detection on CIFAR10](../examples/cd_clf_cifar10.nblink)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}